---
title: "Week 21. Deep into Gym-Pyxis."
excerpt: "Going deeper into the gym-pyxis library and trying to create a simple client."

sidebar:
  nav: "docs"

classes: wide

categories:
- learning

tags:
- logbook
- week 21
- neural_behaviors
- gym pyxies

author: NachoAz
pinned: false



gallery:
  - url: /assets/images/logbook/week21/week21_follow_line_turtlebot.png
    image_path: /assets/images/logbook/week21/week21_follow_line_turtlebot.png
    alt: "Follow Line Turtlebot"

---

## To Do

- [X] Deep into Gym-Pyxis. Execute other examples.
- [X] Check if the GPU is available on the server.

## Progress

This beginning of the year has brought progress in the progress of the work. Small goals have been achieved that create a foundation with which to begin building the core work, teaching a vehicle to follow a line using Reinforcement Learning.

### 1. Deep into Gym-Pyxis. Execute other examples

I continue to learn more about the adapted Gym-Pyxis library. Since it has a connection to Gazebo, I'm trying to run different worlds from Alberto's repository.

An example of a simple world is the one you can see in the next image.

{% include gallery id="gallery" caption="Example of simple world" %}

Some of the worlds generate errors that I will be reviewing but since the goal is not to run all of them I think that with these examples is enough to verify that the installation is correct.

### 1.1 Troubleshooting

Below are different problems in the execution of the Player/stage exercises. Some of the solutions have been obtained from old internet forums. Thank you that these threads are still available :-)

- **Problem**: Executing some examples:

  ```bash
  [ . . . ]
  Resource not found: xacro
  ROS path [0]=/opt/ros/melodic/share/ros
  ROS path [1]=/opt/ros/melodic/share
  The traceback for the exception was written to the log file
  ```

- **Solved** installing:

  ```bash
  sudo apt install ros-melodic-turtlebot3-description
  ```

Exporting the robot's environment variable (typically the 'burger' robot)

  ```bash
  export TURTLEBOT3_MODEL="burger"
  ```

- Copying the worlds and models to the JdeRobot folder:
  - `cp assets/worlds/* /opt/jderobot/share/jderobot/gazebo/worlds/`
  - `cp assets/models/* /opt/jderobot/share/jderobot/gazebo/models/`

Executing the following world:

  ```bash
  roslaunch turtlebot3_followline.launch
  ```

Pyhon dependences (including in `requirements`):

  ```bash
  PyYaml
  rospkg==1.2.3
  ```

### 2. Check if the GPU is available on the server

To check if the GPU is available on the server I tried two things:

- Launch the available command in the TensorFlow documentation that checks if the GPU is available (verifying that the installed library is `tensorflow-gpu`). The output from this command is not what we would want since it returns a `False`.

- The other way is to [check if it is available using the PyTorch library](https://stackoverflow.com/questions/48152674/how-to-check-if-pytorch-is-using-the-gpu). PyTorch simplifies the use of the graphics card (with less libraries the GPU can be used) so I created an empty virtual environment and installed the library. As in the previous case, you check with a series of commands if the GPU is available and the result is the same.

We can therefore deduce that we need to check the installation of the drivers (CUDA, nvcc, etc).

## Working

I'm currently trying to create a simple client that will allow access to the motore and be able to move the robot from the simple world shown in the previous point. If this goes well, I will do the same with the robot's camera.

## Learned

Having solved the problem of compilation we are faced with the next point: learning how to use the library. This again opens a new learning window that I'm starting to cross right now.


